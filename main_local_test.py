import os

import torch

from exp_model_comparsion.online_exp import OnlineExp, NotEnoughPS

if __name__ == "__main__":
    torch.multiprocessing.set_start_method('spawn')

    """
        The complete data with distance matrix can be downloaded from our support website:
            https://sites.google.com/view/onlinefewshot/home
         
        The data path should change accordingly: 
            source: point to the location of the original UEA Univariate_ts folder
            UEA_data: point to the location in which saves shuffle results, new labels, distance matrix and evaluation results.
            dist_core: cpu_cores to compute the distance matrix
            dist_batch_size: Please lower this value if you encounter out of memory error when computing the distance matrix.
    """

    data_path_args = {
        # "source": "/home/user/FewSig/Univariate_ts",
        # "UEA_data": "/home/user/FewSig/UEA_select",
        "source": "/home/zhongs/btc_mount/Univariate_ts",
        "UEA_data": "/home/zhongs/sdm_results_backup/data_source",
        "dist_core": 20,
        "dist_batch_size": 2000
    }

    """
    Specify the name of the dataset
    complete list of dataset used in the paper is in the resources/UEA_select
    """
    select_name = []
    # select_warp = []
    with open(os.path.join(os.getcwd(), "resources", "UEA_select.txt"), 'r') as f:
        lines = f.readlines()
    for cur_line in lines:
        if "%" in cur_line:
            continue
        # tmp = cur_line.split(',')
        # select_name.append(tmp[0])
        # select_warp.append(int(tmp[1]))
        cur_name = cur_line.replace("\n", "")
        select_name.append(cur_name)

    for name in select_name:
        """
            Arguments for FewSig. 
            target_FPR for the ATDT. 
            LR: learning rate for the SGD applied in NCFAE module. 
        """

        FewSig_args = {
            "target_FPR": 0.005,
            "LR": 0.02,
            "init_gpu_count": 0
        }

        p_init = 5
        max_same = 3
        trail = 30
        total_avail_gpu = 5


        """
        Evaluating FewSig model
        results is an array with length of trail:
            for i'th trail result: results[i]:
                first row is true label. the last row is the pseudo label generated by ATDT. 
                The middle rows are the predicted label from NCFAE with different vote. 
        """
        try:
            fewsig = OnlineExp(name, data_path_args, "FewSig", p_init, trail, max_same, FewSig_args=FewSig_args, gpu_num=total_avail_gpu,
                              select_check=True)
            if fewsig is not None:
                results = fewsig.start()
                'get ave. F1 score of vote = 1,2,3,4'
                f1, ave_f1 = fewsig.get_ave_final_F1()
                'get score of vote = 2'
                # f1, ave_f1 = fewsig.get_ave_final_F1(vote=2)
                print(f1, ave_f1)
        except NotEnoughPS:
            print("Not enough positive samples")

        """
            Evaluating Wei's model
        """
        # try:
        #     wei = OnlineExp(name, data_path_args, "Wei", p_init, trail, max_same)
        #     if wei is not None:
        #         results = wei.start()
        #         f1, ave_f1 = wei.get_ave_final_F1()
        #         print(f1, ave_f1)
        # except NotEnoughPS:
        #     print("Not enough positive samples")


        """
            Evaluating DTWD model
        """
        # try:
        #     dtwd = OnlineExp(name, data_path_args, "DTWD", p_init, trail, max_same)
        #     if dtwd is not None:
        #         results = dtwd.start()
        #         f1, ave_f1 = dtwd.get_ave_final_F1()
        #         print(f1, ave_f1)
        # except NotEnoughPS:
        #     print("Not enough positive samples")


        """
            Evaluating SUCCESS model
        """
        # try:
        #     success = OnlineExp(name, data_path_args, "SUCCESS", p_init, trail, max_same)
        #     if success is not None:
        #         results = success.start()
        #         f1, ave_f1 = success.get_ave_final_F1()
        #         print(f1, ave_f1)
        # except NotEnoughPS:
        #     print("Not enough positive samples")

        """
        Evaluating SSTSC model
        The code fetched from https://github.com/mrxiliang/sstsc
        SSTSC model parameters can be set in method online_exp.sstsc_multi_gpu_helper
        
        SSTSC_args: 
            process_num: run experiment parallel, since each testing is independent.
            batch_size: mini-batch for the model
            include_val_score: whether to include the score on validation set to the final score. 
        """
        # SSTSC_args = {
        #     "process_num": 16,
        #     "batch_size": 256,
        #     "include_val_score": True
        # }
        # try:
        #     sstsc = OnlineExp(name, data_path_args, "SSTSC", p_init, trail, max_same, sstsc_args=SSTSC_args, gpu_num=total_avail_gpu)
        #     if sstsc is not None:
        #         results = sstsc.start()
        #         f1, ave_f1 = sstsc.get_ave_final_F1()
        #         print(f1, ave_f1)
        # except NotEnoughPS:
        #     print("Not enough positive samples")